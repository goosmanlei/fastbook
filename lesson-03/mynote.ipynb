{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82f6360",
   "metadata": {},
   "source": [
    "# 张量\n",
    "## 概念\n",
    "- 可以看做就是一个数组，但是它可以在多个维度上进行操作；\n",
    "- 0维张量就是一个数值变量，N维张量就是一个N维数组；\n",
    "- 区别于数组，张量可以在多个维度进行并行计算（例如，在多个样本上同时进行计算，因为每个样本的计算是独立的），这使得它在深度学习中非常重要；\n",
    "- 张量可以在多个样本上同时进行计算，这也是GPU这样的并行计算设备的优势所在，因为GPU可以同时在多个核心上进行计算。\n",
    "\n",
    "## 张量的运算\n",
    "张量的运算可以分为四个大类：元素级运算、形状变换运算、归约运算、线性代数运算\n",
    "\n",
    "### 元素级运算\n",
    "元素级运算就是对张量的每个元素进行操作，例如加法、减法、乘法、除法等，不改变张量的形状。\n",
    "\n",
    "元素级运算有三大类：算术运算、数学函数运算、比较运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fd9d4",
   "metadata": {},
   "source": [
    "#### 算术运行的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算术运行的示例\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print('a = ', a)\n",
    "print('b = ', b)\n",
    "\n",
    "print('a * 3', a * 3)\n",
    "print('a + b =', a + b)\n",
    "print('a - 1 =', a - 1)\n",
    "print('b / 2 =', b / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fddfc",
   "metadata": {},
   "source": [
    "#### 数学函数运算的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print('a = ', a)\n",
    "print('b = ', b)\n",
    "\n",
    "print('torch.sin(a) = ', torch.sin(a))\n",
    "#  clamp 函数将 a 中的所有元素限制在 [0, 5] 之间(小于 0 的元素被设为 0，大于 5 的元素被设为 5)\n",
    "print('torch.clamp(a, min=0, max=5) = ', torch.clamp(a, min=0, max=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c336a53",
   "metadata": {},
   "source": [
    "#### 比较运算的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e06678",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print('a = ', a)\n",
    "print('b = ', b)\n",
    "\n",
    "print('a > b = ', a > b)\n",
    "print('a >= b = ', a >= b)\n",
    "print('a < b = ', a < b)\n",
    "print('a <= b = ', a <= b)\n",
    "print('a == b = ', a == b)\n",
    "print('a != b = ', a != b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e565f81",
   "metadata": {},
   "source": [
    "### 形状变换运算\n",
    "\n",
    "这类运算仅改变张量的维度排列/形状，不修改元素本身，是工程编程中处理多位数组的核心操作。\n",
    "\n",
    "#### 重塑形状\n",
    "元素总数不变的前提下，修改张量的维度分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf289939",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('a =', a)\n",
    "\n",
    "print('a.reshape(1, 6) =', a.reshape(1, 6))\n",
    "print('a.reshape(1, 1, 2, 3) =', a.reshape(1, 1, 2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290df5f",
   "metadata": {},
   "source": [
    "#### 维度增减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ae2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('a =', a)\n",
    "print('a.shape =', a.shape)\n",
    "\n",
    "print('a.unsqueeze(0) =', a.unsqueeze(0))\n",
    "print('a.unsqueeze(0).shape =', a.unsqueeze(0).shape)\n",
    "\n",
    "print('a.unsqueeze(2) =', a.unsqueeze(2))\n",
    "print('a.unsqueeze(2).shape =', a.unsqueeze(2).shape)\n",
    "\n",
    "print('a.squeeze(0).squeeze(0) =', a.squeeze(0).squeeze(0))\n",
    "print('a.squeeze(0).squeeze(0).shape =', a.squeeze(0).squeeze(0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365ac5d",
   "metadata": {},
   "source": [
    "#### 转置与维度置换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('a =', a)\n",
    "print('a.shape =', a.shape)\n",
    "\n",
    "print('a.t() =', a.t())\n",
    "print('a.t().shape =', a.t().shape)\n",
    "\n",
    "img = torch.randn(3, 16, 16)\n",
    "print('img.shape =', img.shape)\n",
    "print('img.permute(1, 0, 2).shape =', img.permute(1, 0, 2).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884ab7b",
   "metadata": {},
   "source": [
    "#### 拼接与分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95050b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接两个(2,2)张量沿维度0（行方向）\n",
    "a1 = torch.tensor([[1,2],[3,4]])\n",
    "a2 = torch.tensor([[5,6],[7,8]])\n",
    "a_cat = torch.cat([a1, a2], dim=0)  # 结果为(4,2)张量\n",
    "print('a_cat =', a_cat)\n",
    "print('a_cat.shape =', a_cat.shape)\n",
    "b_cat = torch.cat([a1, a2], dim=1)  # 结果为(2,4)张量\n",
    "print('b_cat =', b_cat)\n",
    "print('b_cat.shape =', b_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760b578",
   "metadata": {},
   "source": [
    "### 归约运算\n",
    "\n",
    "这类运算的核心，是对张量的指定维度进行聚合统计，降低张量的维度，对应工程编程中的数组求和、求积、求均值等操作（reduce）。\n",
    "\n",
    "常用归约运算有：求和（torch.sum）、求均值（torch.mean）、求最大值（torch.max）、求最小值（torch.min）、求累积和（torch.cumsum）、求方差（torch.var）等\n",
    "\n",
    "可以指定dim参数控制按照哪个维度进行归约运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义(2,3)张量\n",
    "l = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)\n",
    "print('l =', l)\n",
    "print('l.shape =', l.shape)\n",
    "\n",
    "# 对整个张量求和（返回标量）\n",
    "l_sum = torch.sum(l)  # 结果：21.0\n",
    "print('l_sum =', l_sum)\n",
    "print('l_sum.shape =', l_sum.shape)\n",
    "\n",
    "# 沿维度1（列方向）求和（降维为(2,)）\n",
    "l_sum_dim1 = torch.sum(l, dim=1)  # 结果：[6.0, 15.0]\n",
    "print('l_sum_dim1 =', l_sum_dim1)\n",
    "print('l_sum_dim1.shape =', l_sum_dim1.shape)\n",
    "\n",
    "# 沿维度0（行方向）求均值（降维为(3,)）\n",
    "l_mean_dim0 = torch.mean(l, dim=0)  # 结果：[2.5, 3.5, 4.5]\n",
    "print('l_mean_dim0 =', l_mean_dim0)\n",
    "print('l_mean_dim0.shape =', l_mean_dim0.shape)\n",
    "\n",
    "# 归约后默认删除被聚合维度，设置keepdim=True可以保留被聚合维度\n",
    "l_sum_dim1_keep = torch.sum(l, dim=1, keepdim=True)  # 结果：[[6.0], [15.0]]\n",
    "print('l_sum_dim1_keep =', l_sum_dim1_keep)\n",
    "print('l_sum_dim1_keep.shape =', l_sum_dim1_keep.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaec9ef",
   "metadata": {},
   "source": [
    "### 线性代数运算\n",
    "\n",
    "这类运算基于线性代数理论，主要针对二维张量（矩阵）和高维张量（如卷积层的输出），是深度学习中模型训练（如权重更新、矩阵乘法）的核心运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2维张量（矩阵）乘法\n",
    "m = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "print(\"矩阵m：\\n\", m)\n",
    "\n",
    "n = torch.tensor([[5,6],[7,8]], dtype=torch.float32)\n",
    "print(\"矩阵n：\\n\", n)\n",
    "\n",
    "o = torch.matmul(m, n)  # 等价于 m @ n\n",
    "print(\"矩阵乘法结果：\\n\", o)\n",
    "\n",
    "# 2维张量的逆矩阵\n",
    "m_inv = torch.inverse(m)\n",
    "print(\"矩阵逆结果：\\n\", m_inv)\n",
    "\n",
    "# 2维张量的行列式\n",
    "m_det = torch.det(m)\n",
    "print(\"矩阵m的行列式：\\n\", m_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b37934",
   "metadata": {},
   "source": [
    "## 张量的广播机制\n",
    "\n",
    "张量的广播机制，是指在进行张量运算时，自动调整张量的形状，使它们的形状兼容，从而可以进行逐元素的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a0d53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m =  tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "n =  tensor([4, 5, 6])\n",
      "o =  tensor([[ 5,  7,  9],\n",
      "        [ 8, 10, 12],\n",
      "        [11, 13, 15]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的广播机制示例\n",
    "m = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "n = torch.tensor([4, 5, 6])\n",
    "o = m + n\n",
    "\n",
    "print('m = ', m)\n",
    "print('n = ', n)\n",
    "print('o = ', o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5273d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
       "         8.8889, 10.0000])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
